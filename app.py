# import streamlit as st
# import tensorflow as tf
# from PIL import Image
# import numpy as np
# import time

# st.set_page_config(page_title="Human Detection ", page_icon="ğŸ‘¤", layout="wide")

# st.markdown("""
#     <style>
#     .stRadio [data-testid="stMarkdownContainer"] p { font-size: 18px; font-weight: bold; }
#     div[data-testid="stMetric"] { background-color: #ffffff; padding: 15px; border-radius: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
#     .main { background-color: #f0f2f6; }
#     </style>
#     """, unsafe_allow_html=True)

# st.markdown("""
#     <style>
#     .stRadio [data-testid="stMarkdownContainer"] p { font-size: 18px; font-weight: bold; }
#     div[data-testid="stMetric"] { background-color: #ffffff; padding: 15px; border-radius: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
#     .main { background-color: #f0f2f6; }

#     /* 1. Láº­t ngÆ°á»£c camera khi Ä‘ang soi */
#     video {
#         transform: scaleX(-1);
#         -webkit-transform: scaleX(-1);
#     }

#     /* 2. Láº­t ngÆ°á»£c cÃ¡i áº£nh Káº¾T QUáº¢ sau khi chá»¥p tá»« camera */
#     /* CSS nÃ y chá»‰ tÃ¡c Ä‘á»™ng vÃ o áº£nh Ä‘Æ°á»£c táº¡o ra tá»« st.camera_input */
#     [data-testid="stCameraInput"] img {
#         transform: scaleX(-1);
#         -webkit-transform: scaleX(-1);
#     }
#     </style>
#     """, unsafe_allow_html=True)
# st.markdown("""
#     <style>
#     /* Láº­t ngÆ°á»£c áº£nh hiá»ƒn thá»‹ trong pháº§n káº¿t quáº£ dá»± Ä‘oÃ¡n */
#     [data-testid="stImage"] img {
#         transform: scaleX(-1);
#         -webkit-transform: scaleX(-1);
#     }
#     </style>
#     """, unsafe_allow_html=True)

# @st.cache_resource
# def load_my_model():
#     try:
#         base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights=None)
#         model = tf.keras.Sequential([
#             base_model,
#             tf.keras.layers.GlobalAveragePooling2D(),
#             tf.keras.layers.Dense(1, activation='sigmoid')
#         ])
#         model.load_weights('model_weights.weights.h5')
#         return model
#     except Exception as e:
#         st.error(f"Lá»—i há»‡ thá»‘ng: {e}")
#         return None

# model = load_my_model()

# st.write("<h1 style='text-align: center; color: #1E3A8A;'>ğŸ¯ Há»† THá»NG NHáº¬N DIá»†N NGÆ¯á»œI</h1>", unsafe_allow_html=True)
# st.divider()

# if 'input_method' not in st.session_state:
#     st.session_state.input_method = None

# col1, col2 = st.columns([1, 1.2], gap="large")

# with col1:
#     st.markdown("### ğŸ“¥ Chá»n phÆ°Æ¡ng thá»©c nháº­p")
    
#     c1, c2 = st.columns(2)
#     if c1.button("ğŸ“ Táº£i áº£nh lÃªn", use_container_width=True):
#         st.session_state.input_method = "upload"
#     if c2.button("ğŸ“· DÃ¹ng Webcam", use_container_width=True):
#         st.session_state.input_method = "camera"

#     img_data = None

#     if st.session_state.input_method == "upload":
#         img_data = st.file_uploader("KÃ©o tháº£ file hÃ¬nh áº£nh...", type=["jpg", "png", "jpeg"])
    
#     elif st.session_state.input_method == "camera":
#         img_data = st.camera_input("Chá»¥p áº£nh Ä‘á»ƒ phÃ¢n tÃ­ch")
 

# with col2:
#     st.markdown("### ğŸ” PhÃ¢n tÃ­ch ")
#     if img_data is not None:
#         image = Image.open(img_data).convert('RGB')
#         st.image(image, caption='Dá»¯ liá»‡u Ä‘áº§u vÃ o', use_container_width=True)
        
#         if model is not None:
#             with st.spinner('Äang quÃ©t hÃ¬nh áº£nh...'):
                
#                 img_resized = image.resize((224, 224))
#                 img_array = np.array(img_resized).astype(np.float32) / 255.0
#                 img_array = np.expand_dims(img_array, axis=0)
            
#                 prediction = model.predict(img_array)
#                 prob = float(prediction[0][0])
#                 time.sleep(0.4)

#             st.markdown("---")
            
#             if prob < 0.5:
#                 confidence = (1 - prob) * 100
#                 st.success(f"## âœ… Káº¾T LUáº¬N: ÄÃ‚Y LÃ€ NGÆ¯á»œI")
#                 st.balloons()
#             else:
#                 confidence = prob * 100
#                 st.error(f"## âŒ Káº¾T LUáº¬N: KHÃ”NG PHáº¢I NGÆ¯á»œI")
#     else:
#         st.info("Há»‡ thá»‘ng Ä‘ang sáºµn sÃ ng. HÃ£y cung cáº¥p hÃ¬nh áº£nh Ä‘á»ƒ báº¯t Ä‘áº§u.")

# with st.sidebar:
#     st.markdown(f"""
#     **Há» tÃªn:** LÃª Äáº·ng Tuáº¥n Báº£o  
#     **MSV:** 223332815  
#     **Lá»›p:** RB&AI-K63  
#     ---
#     **CÃ´ng nghá»‡:**
#     - CNN MobileNetV2
#     - Streamlit Cloud
#     """)
#     st.divider()
#     st.caption("Â© 2026 AI Project Solution")



import streamlit as st
import tensorflow as tf
from PIL import Image, ImageOps # ThÃªm ImageOps Ä‘á»ƒ láº­t áº£nh
import numpy as np
import time

# --- Cáº¤U HÃŒNH TRANG ---
st.set_page_config(page_title="Human Detection", page_icon="ğŸ‘¤", layout="wide")

# --- CSS TÃ™Y CHá»ˆNH ---
st.markdown("""
    <style>
    .stRadio [data-testid="stMarkdownContainer"] p { font-size: 18px; font-weight: bold; }
    div[data-testid="stMetric"] { background-color: #ffffff; padding: 15px; border-radius: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
    .main { background-color: #f0f2f6; }

    /* Láº­t ngÆ°á»£c luá»“ng video soi gÆ°Æ¡ng cho Webcam lÃºc Ä‘ang soi */
    video {
        transform: scaleX(-1);
        -webkit-transform: scaleX(-1);
    }
    </style>
    """, unsafe_allow_html=True)

# --- LOAD MODEL ---
@st.cache_resource
def load_my_model():
    try:
        base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights=None)
        model = tf.keras.Sequential([
            base_model,
            tf.keras.layers.GlobalAveragePooling2D(),
            tf.keras.layers.Dense(1, activation='sigmoid')
        ])
        model.load_weights('model_weights.weights.h5')
        return model
    except Exception as e:
        st.error(f"Lá»—i há»‡ thá»‘ng: {e}")
        return None

model = load_my_model()

# --- GIAO DIá»†N CHÃNH ---
st.write("<h1 style='text-align: center; color: #1E3A8A;'>ğŸ¯ Há»† THá»NG NHáº¬N DIá»†N NGÆ¯á»œI</h1>", unsafe_allow_html=True)
st.divider()

if 'input_method' not in st.session_state:
    st.session_state.input_method = None

col1, col2 = st.columns([1, 1.2], gap="large")

with col1:
    st.markdown("### ğŸ“¥ Chá»n phÆ°Æ¡ng thá»©c nháº­p")
    
    c1, c2 = st.columns(2)
    if c1.button("ğŸ“ Táº£i áº£nh lÃªn", use_container_width=True):
        st.session_state.input_method = "upload"
    if c2.button("ğŸ“· DÃ¹ng Webcam", use_container_width=True):
        st.session_state.input_method = "camera"

    img_data = None
    if st.session_state.input_method == "upload":
        img_data = st.file_uploader("KÃ©o tháº£ file hÃ¬nh áº£nh...", type=["jpg", "png", "jpeg"])
    elif st.session_state.input_method == "camera":
        img_data = st.camera_input("Chá»¥p áº£nh Ä‘á»ƒ phÃ¢n tÃ­ch")

with col2:
    st.markdown("### ğŸ” PhÃ¢n tÃ­ch ")
    if img_data is not None:
        # 1. Má»Ÿ áº£nh tá»« dá»¯ liá»‡u Ä‘áº§u vÃ o
        image = Image.open(img_data).convert('RGB')
        
        # 2. Xá»¬ LÃ Láº¬T áº¢NH Náº¾U DÃ™NG CAMERA
        if st.session_state.input_method == "camera":
            # Láº­t ngÆ°á»£c áº£nh váº­t lÃ½ Ä‘á»ƒ hiá»ƒn thá»‹ vÃ  Ä‘Æ°a vÃ o AI Ä‘á»“ng nháº¥t vá»›i lÃºc soi gÆ°Æ¡ng
            image = ImageOps.mirror(image)
            st.image(image, caption='Káº¿t quáº£ chá»¥p (ÄÃ£ láº­t gÆ°Æ¡ng)', use_container_width=True)
        else:
            # Náº¿u táº£i lÃªn tá»« mÃ¡y tÃ­nh, giá»¯ nguyÃªn khÃ´ng láº­t
            st.image(image, caption='áº¢nh gá»‘c táº£i lÃªn', use_container_width=True)
        
        # 3. Dá»° ÄOÃN
        if model is not None:
            with st.spinner('Äang quÃ©t hÃ¬nh áº£nh...'):
                img_resized = image.resize((224, 224))
                img_array = np.array(img_resized).astype(np.float32) / 255.0
                img_array = np.expand_dims(img_array, axis=0)
            
                prediction = model.predict(img_array)
                prob = float(prediction[0][0])
                time.sleep(0.4)

            st.markdown("---")
            
            # Káº¿t luáº­n (Dá»±a trÃªn logic cá»§a báº¡n: < 0.5 lÃ  NgÆ°á»i)
            if prob < 0.5:
                st.success(f"## âœ… Káº¾T LUáº¬N: ÄÃ‚Y LÃ€ NGÆ¯á»œI")
                st.balloons()
            else:
                st.error(f"## âŒ Káº¾T LUáº¬N: KHÃ”NG PHáº¢I NGÆ¯á»œI")
    else:
        st.info("Há»‡ thá»‘ng Ä‘ang sáºµn sÃ ng. HÃ£y cung cáº¥p hÃ¬nh áº£nh Ä‘á»ƒ báº¯t Ä‘áº§u.")

# --- SIDEBAR ---
with st.sidebar:
    st.markdown(f"""
    **Há» tÃªn:** LÃª Äáº·ng Tuáº¥n Báº£o  
    **MSV:** 223332815  
    **Lá»›p:** RB&AI-K63  
    ---
    **CÃ´ng nghá»‡:**
    - CNN MobileNetV2
    - Streamlit Cloud
    """)
    st.divider()
    st.caption("Â© 2026 AI Project Solution")
















