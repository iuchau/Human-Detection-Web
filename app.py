import streamlit as st
import tensorflow as tf
from PIL import Image, ImageOps
import numpy as np
import time

st.set_page_config(page_title="Human Detection", page_icon="üë§", layout="wide")

st.markdown("""
    <style>
    .stRadio [data-testid="stMarkdownContainer"] p { font-size: 18px; font-weight: bold; }
    div[data-testid="stMetric"] { background-color: #ffffff; padding: 15px; border-radius: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
    .main { background-color: #f0f2f6; }

    /* 1. L·∫≠t ng∆∞·ª£c lu·ªìng video l√∫c ƒëang soi webcam */
    video {
        transform: scaleX(-1);
        -webkit-transform: scaleX(-1);
    }

    /* 2. L·∫≠t ng∆∞·ª£c ·∫£nh k·∫øt qu·∫£ hi·ªÉn th·ªã NGAY TRONG widget camera_input sau khi ch·ª•p */
    [data-testid="stCameraInput"] img {
        transform: scaleX(-1);
        -webkit-transform: scaleX(-1);
    }
    </style>
    """, unsafe_allow_html=True)
st.markdown("""
    <style>
    /* T·ªïng th·ªÉ giao di·ªán */
    .main { background-color: #f8f9fa; }
    
    /* T√πy ch·ªânh ti√™u ƒë·ªÅ v√† text */
    .stMarkdown h3 { color: #1E3A8A; margin-bottom: 20px; }

    /* 1. L√†m ƒë·∫πp khung Camera Input */
    [data-testid="stCameraInput"] {
        border: 3px solid #1E3A8A;
        border-radius: 20px;
        padding: 10px;
        background: linear-gradient(145deg, #ffffff, #e6e6e6);
        box-shadow: 0 10px 25px rgba(30, 58, 138, 0.2);
        overflow: hidden;
    }

    /* 2. Hi·ªáu ·ª©ng cho n√∫t b·∫•m trong Camera Input */
    [data-testid="stCameraInput"] button {
        background-color: #1E3A8A !important;
        color: white !important;
        border-radius: 10px !important;
        transition: all 0.3s ease;
    }

    [data-testid="stCameraInput"] button:hover {
        transform: scale(1.02);
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
    }

    /* 3. L·∫≠t ng∆∞·ª£c video webcam (Mirror) */
    video {
        transform: scaleX(-1);
        -webkit-transform: scaleX(-1);
        border-radius: 12px;
    }

    /* 4. L·∫≠t ng∆∞·ª£c ·∫£nh k·∫øt qu·∫£ hi·ªÉn th·ªã sau khi ch·ª•p */
    [data-testid="stCameraInput"] img {
        transform: scaleX(-1);
        -webkit-transform: scaleX(-1);
        border-radius: 12px;
    }

    /* Bo g√≥c khung t·∫£i file */
    [data-testid="stFileUploader"] {
        border: 2px dashed #1E3A8A;
        border-radius: 15px;
        padding: 15px;
    }
    </style>
    """, unsafe_allow_html=True)

@st.cache_resource
def load_my_model():
    try:
        base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights=None)
        model = tf.keras.Sequential([
            base_model,
            tf.keras.layers.GlobalAveragePooling2D(),
            tf.keras.layers.Dense(1, activation='sigmoid')
        ])
        model.load_weights('model_weights.weights.h5')
        return model
    except Exception as e:
        st.error(f"L·ªói h·ªá th·ªëng: {e}")
        return None

model = load_my_model()

st.write("<h1 style='text-align: center; color: #1E3A8A;'>üéØ H·ªÜ TH·ªêNG NH·∫¨N DI·ªÜN NG∆Ø·ªúI</h1>", unsafe_allow_html=True)
st.divider()

if 'input_method' not in st.session_state:
    st.session_state.input_method = None

col1, col2 = st.columns([1, 1.2], gap="large")

with col1:
    st.markdown("### üì• Ch·ªçn ph∆∞∆°ng th·ª©c nh·∫≠p")
    c1, c2 = st.columns(2)
    if c1.button("üìÅ T·∫£i ·∫£nh l√™n", use_container_width=True):
        st.session_state.input_method = "upload"
    if c2.button("üì∑ D√πng Webcam", use_container_width=True):
        st.session_state.input_method = "camera"

    img_data = None
    if st.session_state.input_method == "upload":
        img_data = st.file_uploader("K√©o th·∫£ file h√¨nh ·∫£nh...", type=["jpg", "png", "jpeg"])
    elif st.session_state.input_method == "camera":
        
        img_data = st.camera_input("Ch·ª•p ·∫£nh ƒë·ªÉ ph√¢n t√≠ch")

with col2:
    st.markdown("### üîç Ph√¢n t√≠ch ")
    if img_data is not None:
        image = Image.open(img_data).convert('RGB')
        
        if st.session_state.input_method == "camera":
            
            image = ImageOps.mirror(image)
            st.image(image, caption='K·∫øt qu·∫£ ch·ª•p', use_container_width=True)
        else:
            st.image(image, caption='D·ªØ li·ªáu t·∫£i l√™n', use_container_width=True)
        
        if model is not None:
            with st.spinner('ƒêang ph√¢n t√≠ch...'):
                img_resized = image.resize((224, 224))
                img_array = np.array(img_resized).astype(np.float32) / 255.0
                img_array = np.expand_dims(img_array, axis=0)
                prediction = model.predict(img_array)
                prob = float(prediction[0][0])
                time.sleep(0.4)

            st.markdown("---")
            if prob < 0.5:
                st.success(f"## ‚úÖ K·∫æT LU·∫¨N: ƒê√ÇY L√Ä NG∆Ø·ªúI")
                st.balloons()
            else:
                st.error(f"## ‚ùå K·∫æT LU·∫¨N: KH√îNG PH·∫¢I NG∆Ø·ªúI")
    else:
        st.info("H·ªá th·ªëng ƒëang s·∫µn s√†ng. H√£y cung c·∫•p h√¨nh ·∫£nh ƒë·ªÉ b·∫Øt ƒë·∫ßu.")

with st.sidebar:
    st.markdown(f"""
    **H·ªç t√™n:** L√™ ƒê·∫∑ng Tu·∫•n B·∫£o  
    **MSV:** 223332815  
    **L·ªõp:** RB&AI-K63  
    ---
    **C√¥ng ngh·ªá:**
    - CNN MobileNetV2
    - Streamlit Cloud
    """)
    st.divider()
    st.caption("¬© 2026 AI Project Solution")


