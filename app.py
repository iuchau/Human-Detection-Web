# import streamlit as st
# import tensorflow as tf
# from PIL import Image
# import numpy as np
# import time

# st.set_page_config(page_title="Human Detection ", page_icon="üë§", layout="wide")

# st.markdown("""
#     <style>
#     .stRadio [data-testid="stMarkdownContainer"] p { font-size: 18px; font-weight: bold; }
#     div[data-testid="stMetric"] { background-color: #ffffff; padding: 15px; border-radius: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
#     .main { background-color: #f0f2f6; }
#     </style>
#     """, unsafe_allow_html=True)

# st.markdown("""
#     <style>
#     .stRadio [data-testid="stMarkdownContainer"] p { font-size: 18px; font-weight: bold; }
#     div[data-testid="stMetric"] { background-color: #ffffff; padding: 15px; border-radius: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
#     .main { background-color: #f0f2f6; }

#     /* 1. L·∫≠t ng∆∞·ª£c camera khi ƒëang soi */
#     video {
#         transform: scaleX(-1);
#         -webkit-transform: scaleX(-1);
#     }

#     /* 2. L·∫≠t ng∆∞·ª£c c√°i ·∫£nh K·∫æT QU·∫¢ sau khi ch·ª•p t·ª´ camera */
#     /* CSS n√†y ch·ªâ t√°c ƒë·ªông v√†o ·∫£nh ƒë∆∞·ª£c t·∫°o ra t·ª´ st.camera_input */
#     [data-testid="stCameraInput"] img {
#         transform: scaleX(-1);
#         -webkit-transform: scaleX(-1);
#     }
#     </style>
#     """, unsafe_allow_html=True)
# st.markdown("""
#     <style>
#     /* L·∫≠t ng∆∞·ª£c ·∫£nh hi·ªÉn th·ªã trong ph·∫ßn k·∫øt qu·∫£ d·ª± ƒëo√°n */
#     [data-testid="stImage"] img {
#         transform: scaleX(-1);
#         -webkit-transform: scaleX(-1);
#     }
#     </style>
#     """, unsafe_allow_html=True)

# @st.cache_resource
# def load_my_model():
#     try:
#         base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights=None)
#         model = tf.keras.Sequential([
#             base_model,
#             tf.keras.layers.GlobalAveragePooling2D(),
#             tf.keras.layers.Dense(1, activation='sigmoid')
#         ])
#         model.load_weights('model_weights.weights.h5')
#         return model
#     except Exception as e:
#         st.error(f"L·ªói h·ªá th·ªëng: {e}")
#         return None

# model = load_my_model()

# st.write("<h1 style='text-align: center; color: #1E3A8A;'>üéØ H·ªÜ TH·ªêNG NH·∫¨N DI·ªÜN NG∆Ø·ªúI</h1>", unsafe_allow_html=True)
# st.divider()

# if 'input_method' not in st.session_state:
#     st.session_state.input_method = None

# col1, col2 = st.columns([1, 1.2], gap="large")

# with col1:
#     st.markdown("### üì• Ch·ªçn ph∆∞∆°ng th·ª©c nh·∫≠p")
    
#     c1, c2 = st.columns(2)
#     if c1.button("üìÅ T·∫£i ·∫£nh l√™n", use_container_width=True):
#         st.session_state.input_method = "upload"
#     if c2.button("üì∑ D√πng Webcam", use_container_width=True):
#         st.session_state.input_method = "camera"

#     img_data = None

#     if st.session_state.input_method == "upload":
#         img_data = st.file_uploader("K√©o th·∫£ file h√¨nh ·∫£nh...", type=["jpg", "png", "jpeg"])
    
#     elif st.session_state.input_method == "camera":
#         img_data = st.camera_input("Ch·ª•p ·∫£nh ƒë·ªÉ ph√¢n t√≠ch")
 

# with col2:
#     st.markdown("### üîç Ph√¢n t√≠ch ")
#     if img_data is not None:
#         image = Image.open(img_data).convert('RGB')
#         st.image(image, caption='D·ªØ li·ªáu ƒë·∫ßu v√†o', use_container_width=True)
        
#         if model is not None:
#             with st.spinner('ƒêang qu√©t h√¨nh ·∫£nh...'):
                
#                 img_resized = image.resize((224, 224))
#                 img_array = np.array(img_resized).astype(np.float32) / 255.0
#                 img_array = np.expand_dims(img_array, axis=0)
            
#                 prediction = model.predict(img_array)
#                 prob = float(prediction[0][0])
#                 time.sleep(0.4)

#             st.markdown("---")
            
#             if prob < 0.5:
#                 confidence = (1 - prob) * 100
#                 st.success(f"## ‚úÖ K·∫æT LU·∫¨N: ƒê√ÇY L√Ä NG∆Ø·ªúI")
#                 st.balloons()
#             else:
#                 confidence = prob * 100
#                 st.error(f"## ‚ùå K·∫æT LU·∫¨N: KH√îNG PH·∫¢I NG∆Ø·ªúI")
#     else:
#         st.info("H·ªá th·ªëng ƒëang s·∫µn s√†ng. H√£y cung c·∫•p h√¨nh ·∫£nh ƒë·ªÉ b·∫Øt ƒë·∫ßu.")

# with st.sidebar:
#     st.markdown(f"""
#     **H·ªç t√™n:** L√™ ƒê·∫∑ng Tu·∫•n B·∫£o  
#     **MSV:** 223332815  
#     **L·ªõp:** RB&AI-K63  
#     ---
#     **C√¥ng ngh·ªá:**
#     - CNN MobileNetV2
#     - Streamlit Cloud
#     """)
#     st.divider()
#     st.caption("¬© 2026 AI Project Solution")



import streamlit as st
import tensorflow as tf
from PIL import Image
import numpy as np
import time

st.set_page_config(page_title="Human Detection", page_icon="üë§", layout="wide")

st.markdown("""
    <style>
    .stRadio [data-testid="stMarkdownContainer"] p { font-size: 18px; font-weight: bold; }
    div[data-testid="stMetric"] { background-color: #ffffff; padding: 15px; border-radius: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
    .main { background-color: #f0f2f6; 

    /* 1. L·∫≠t ng∆∞·ª£c lu·ªìng video tr·ª±c ti·∫øp t·ª´ camera */
    video {
        transform: scaleX(-1);
        -webkit-transform: scaleX(-1);
    }

    /* 2. Class ri√™ng ƒë·ªÉ l·∫≠t ·∫£nh k·∫øt qu·∫£ - CH·ªà d√πng khi ch·ª•p t·ª´ webcam */
    .mirrored-result img {
        transform: scaleX(-1);
        -webkit-transform: scaleX(-1);
    }
    </style>
    """, unsafe_allow_html=True)

# --- LOAD MODEL ---
@st.cache_resource
def load_my_model():
    try:
        base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights=None)
        model = tf.keras.Sequential([
            base_model,
            tf.keras.layers.GlobalAveragePooling2D(),
            tf.keras.layers.Dense(1, activation='sigmoid')
        ])
        model.load_weights('model_weights.weights.h5')
        return model
    except Exception as e:
        st.error(f"L·ªói h·ªá th·ªëng: {e}")
        return None

model = load_my_model()

# --- GIAO DI·ªÜN CH√çNH ---
st.write("<h1 style='text-align: center; color: #1E3A8A;'>üéØ H·ªÜ TH·ªêNG NH·∫¨N DI·ªÜN NG∆Ø·ªúI</h1>", unsafe_allow_html=True)
st.divider()

if 'input_method' not in st.session_state:
    st.session_state.input_method = None

col1, col2 = st.columns([1, 1.2], gap="large")

with col1:
    st.markdown("### üì• Ch·ªçn ph∆∞∆°ng th·ª©c nh·∫≠p")
    
    c1, c2 = st.columns(2)
    if c1.button("üìÅ T·∫£i ·∫£nh l√™n", use_container_width=True):
        st.session_state.input_method = "upload"
    if c2.button("üì∑ D√πng Webcam", use_container_width=True):
        st.session_state.input_method = "camera"

    img_data = None
    if st.session_state.input_method == "upload":
        img_data = st.file_uploader("K√©o th·∫£ file h√¨nh ·∫£nh...", type=["jpg", "png", "jpeg"])
    elif st.session_state.input_method == "camera":
        img_data = st.camera_input("Ch·ª•p ·∫£nh ƒë·ªÉ ph√¢n t√≠ch")

with col2:
    st.markdown("### üîç Ph√¢n t√≠ch ")
    if img_data is not None:
        image = Image.open(img_data).convert('RGB')
        
        # KI·ªÇM TRA PH∆Ø∆†NG TH·ª®C ƒê·ªÇ √ÅP D·ª§NG CSS L·∫¨T ·∫¢NH
        if st.session_state.input_method == "camera":
            # N·∫øu d√πng camera, b·ªçc trong div mirrored-result ƒë·ªÉ l·∫≠t ng∆∞·ª£c ·∫£nh hi·ªÉn th·ªã
            st.markdown('<div class="mirrored-result">', unsafe_allow_html=True)
            st.image(image, caption='D·ªØ li·ªáu t·ª´ Camera (ƒê√£ l·∫≠t g∆∞∆°ng)', use_container_width=True)
            st.markdown('</div>', unsafe_allow_html=True)
        else:
            # N·∫øu t·∫£i ·∫£nh l√™n, hi·ªÉn th·ªã b√¨nh th∆∞·ªùng kh√¥ng l·∫≠t
            st.image(image, caption='D·ªØ li·ªáu t·∫£i l√™n (Gi·ªØ nguy√™n g·ªëc)', use_container_width=True)
        
        if model is not None:
            with st.spinner('ƒêang qu√©t h√¨nh ·∫£nh...'):
                # Ti·ªÅn x·ª≠ l√Ω
                img_resized = image.resize((224, 224))
                img_array = np.array(img_resized).astype(np.float32) / 255.0
                img_array = np.expand_dims(img_array, axis=0)
            
                prediction = model.predict(img_array)
                prob = float(prediction[0][0])
                time.sleep(0.4)

            st.markdown("---")
            
            # K·∫øt lu·∫≠n d·ª±a tr√™n ng∆∞·ª°ng 0.5 (Gi·∫£ ƒë·ªãnh: < 0.5 l√† ng∆∞·ªùi theo logic c≈© c·ªßa b·∫°n)
            if prob < 0.5:
                st.success(f"## ‚úÖ K·∫æT LU·∫¨N: ƒê√ÇY L√Ä NG∆Ø·ªúI")
                st.balloons()
            else:
                st.error(f"## ‚ùå K·∫æT LU·∫¨N: KH√îNG PH·∫¢I NG∆Ø·ªúI")
    else:
        st.info("H·ªá th·ªëng ƒëang s·∫µn s√†ng. H√£y cung c·∫•p h√¨nh ·∫£nh ƒë·ªÉ b·∫Øt ƒë·∫ßu.")

# --- SIDEBAR ---
with st.sidebar:
    st.markdown(f"""
    **H·ªç t√™n:** L√™ ƒê·∫∑ng Tu·∫•n B·∫£o  
    **MSV:** 223332815  
    **L·ªõp:** RB&AI-K63  
    ---
    **C√¥ng ngh·ªá:**
    - CNN MobileNetV2
    - Streamlit Cloud
    """)
    st.divider()
    st.caption("¬© 2026 AI Project Solution")
















