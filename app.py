# import streamlit as st
# import tensorflow as tf
# from PIL import Image
# import numpy as np

# # 1. C·∫•u h√¨nh giao di·ªán
# st.set_page_config(page_title="H·ªá Th·ªëng Nh·∫≠n Di·ªán Ng∆∞·ªùi", layout="centered")
# st.title("üë§ Nh·∫≠n Di·ªán Ng∆∞·ªùi ")

# # 2. H√†m n·∫°p m√¥ h√¨nh (Khung Sequential ch·ªëng l·ªói 2 tensors)
# @st.cache_resource
# def load_my_model():
#     try:
#         base_model = tf.keras.applications.MobileNetV2(
#             input_shape=(224, 224, 3), include_top=False, weights=None
#         )
#         model = tf.keras.Sequential([
#             base_model,
#             tf.keras.layers.GlobalAveragePooling2D(),
#             tf.keras.layers.Dense(1, activation='sigmoid')
#         ])
#         model.load_weights('model_weights.weights.h5')
#         return model
#     except Exception as e:
#         st.error(f"L·ªói n·∫°p m√¥ h√¨nh: {e}")
#         return None

# model = load_my_model()

# # 3. L·ª±a ch·ªçn ngu·ªìn ·∫£nh
# st.subheader("Ch·ªçn ngu·ªìn d·ªØ li·ªáu:")
# source = st.radio("H√¨nh th·ª©c:", ("T·∫£i ·∫£nh l√™n", "Ch·ª•p ·∫£nh tr·ª±c ti·∫øp"))

# img_data = None

# if source == "T·∫£i ·∫£nh l√™n":
#     img_data = st.file_uploader("Ch·ªçn file ·∫£nh...", type=["jpg", "png", "jpeg"])
# else:
#     img_data = st.camera_input("ƒê∆∞a m·∫∑t v√†o khung h√¨nh ƒë·ªÉ ch·ª•p")

# # 4. X·ª≠ l√Ω d·ª± ƒëo√°n
# if img_data is not None:
#     # M·ªü ·∫£nh v√† chu·∫©n h√≥a
#     image = Image.open(img_data).convert('RGB')
    
#     # Hi·ªÉn th·ªã ·∫£nh (ch·ªâ d√†nh cho ·∫£nh t·∫£i l√™n, camera ƒë√£ c√≥ khung xem tr∆∞·ªõc)
#     if source == "T·∫£i ·∫£nh l√™n":
#         st.image(image, caption='·∫¢nh ƒë√£ ch·ªçn', use_container_width=True)
    
#     if st.button('üöÄ B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán'):
#         if model is not None:
#             # Ti·ªÅn x·ª≠ l√Ω ·∫£nh
#             img_resized = image.resize((224, 224))
#             img_array = np.array(img_resized).astype(np.float32) / 255.0
#             img_array = np.expand_dims(img_array, axis=0)
            
#             # D·ª± ƒëo√°n
#             prediction = model.predict(img_array)
#             prob = float(prediction[0][0])
            
#             # Hi·ªÉn th·ªã k·∫øt qu·∫£ cu·ªëi c√πng (ƒê√£ x√≥a d√≤ng hi·ªÉn th·ªã ch·ªâ s·ªë)
#             st.markdown("---")
            
#             # Ghi ch√∫: N·∫øu k·∫øt qu·∫£ b·ªã ng∆∞·ª£c (ng∆∞·ªùi b√°o kh√¥ng ph·∫£i ng∆∞·ªùi), h√£y ƒë·ªïi d·∫•u > th√†nh <
#             if prob < 0.5:
#                 st.success("‚úÖ K·∫æT QU·∫¢: ƒê√ÇY L√Ä NG∆Ø·ªúI")
#                 st.balloons()
#             else:
#                 st.error("‚ùå K·∫æT QU·∫¢: KH√îNG PH·∫¢I NG∆Ø·ªúI")
#         else:
#             st.error("Model ch∆∞a s·∫µn s√†ng.")

# # Sidebar th√¥ng tin d·ª± √°n
# st.sidebar.markdown("### Th√¥ng Tin Sinh Vi√™n")

# st.sidebar.info("H·ªç T√™n: L√™ ƒê·∫∑ng Tu·∫•n B·∫£o")
# st.sidebar.info("MSV: 223332815")
# st.sidebar.info("L·ªõp: RB&AI-K63")

# import streamlit as st
# import tensorflow as tf
# from PIL import Image
# import numpy as np
# import time

# # 1. C·∫•u h√¨nh trang (M·ªü r·ªông layout v√† th√™m favicon)
# st.set_page_config(
#     page_title="Human Detection",
#     page_icon="üë§",
#     layout="wide"
# )

# # Th√™m CSS t√πy ch·ªânh ƒë·ªÉ l√†m ƒë·∫πp giao di·ªán
# st.markdown("""
#     <style>
#     .main { background-color: #f8f9fa; }
#     .stButton>button {
#         width: 100%;
#         border-radius: 20px;
#         height: 3em;
#         background-color: #4CAF50;
#         color: white;
#         font-weight: bold;
#         border: none;
#     }
#     .stButton>button:hover { background-color: #45a049; border: none; }
#     .reportview-container .main .block-container { padding-top: 2rem; }
#     </style>
#     """, unsafe_allow_html=True)

# # 2. H√†m n·∫°p m√¥ h√¨nh
# @st.cache_resource
# def load_my_model():
#     try:
#         base_model = tf.keras.applications.MobileNetV2(
#             input_shape=(224, 224, 3), include_top=False, weights=None
#         )
#         model = tf.keras.Sequential([
#             base_model,
#             tf.keras.layers.GlobalAveragePooling2D(),
#             tf.keras.layers.Dense(1, activation='sigmoid')
#         ])
#         model.load_weights('model_weights.weights.h5')
#         return model
#     except Exception as e:
#         st.error(f"L·ªói n·∫°p m√¥ h√¨nh: {e}")
#         return None

# model = load_my_model()

# # --- TI√äU ƒê·ªÄ CH√çNH ---
# st.write(f"<h1 style='text-align: center; color: #1E3A8A;'>üë§ H·ªá Th·ªëng Nh·∫≠n Di·ªán Ng∆∞·ªùi</h1>", unsafe_allow_html=True)
# st.write(f"<p style='text-align: center; font-style: italic;'>D·ª± √°n H·ªçc S√¢u - C√¥ng ngh·ªá MobileNetV2</p>", unsafe_allow_html=True)
# st.markdown("---")

# # --- B·ªê C·ª§C CH√çNH (2 C·ªôt) ---
# col1, col2 = st.columns([1, 1], gap="large")

# with col1:
#     st.subheader("üì• ƒê·∫ßu V√†o D·ªØ Li·ªáu")
#     # S·ª≠ d·ª•ng Tabs ƒë·ªÉ gom nh√≥m ngu·ªìn ·∫£nh
#     tab1, tab2 = st.tabs(["üìÅ T·∫£i ·∫£nh l√™n", "üì∑ Ch·ª•p tr·ª±c ti·∫øp"])
    
#     img_data = None
#     with tab1:
#         img_data = st.file_uploader("K√©o th·∫£ ho·∫∑c ch·ªçn file...", type=["jpg", "png", "jpeg"])
#     with tab2:
#         img_data = st.camera_input("Ch·ª•p ·∫£nh t·ª´ webcam")

# with col2:
#     st.subheader("üìä K·∫øt Qu·∫£ Ph√¢n T√≠ch")
#     if img_data is not None:
#         image = Image.open(img_data).convert('RGB')
#         st.image(image, caption='·∫¢nh ƒëang x·ª≠ l√Ω', use_container_width=True)
        
#         if st.button('üöÄ PH√ÇN T√çCH NGAY'):
#             if model is not None:
#                 # Hi·ªáu ·ª©ng Spinner cho chuy√™n nghi·ªáp
#                 with st.spinner('ƒêang ch·∫°y thu·∫≠t to√°n Deep Learning...'):
#                     # Ti·ªÅn x·ª≠ l√Ω
#                     img_resized = image.resize((224, 224))
#                     img_array = np.array(img_resized).astype(np.float32) / 255.0
#                     img_array = np.expand_dims(img_array, axis=0)
                    
#                     # D·ª± ƒëo√°n
#                     prediction = model.predict(img_array)
#                     prob = float(prediction[0][0])
                    
#                     # M√¥ ph·ªèng th·ªùi gian ch·ªù cho AI
#                     time.sleep(0.5)
                
#                 # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
#                 st.markdown("### K·∫øt lu·∫≠n c·ªßa AI:")
                
#                 # Logic ph√¢n lo·∫°i (L∆∞u √Ω d·∫•u < 0.5 theo y√™u c·∫ßu c·ªßa b·∫°n)
#                 if prob < 0.5:
#                     confidence = (1 - prob) * 100
#                     st.success(f"## ‚úÖ ƒê√ÇY L√Ä NG∆Ø·ªúI")
#                     st.metric(label="ƒê·ªô tin c·∫≠y", value=f"{confidence:.2f}%")
#                     st.balloons()
#                 else:
#                     confidence = prob * 100
#                     st.error(f"## ‚ùå KH√îNG PH·∫¢I NG∆Ø·ªúI")
#                     st.metric(label="ƒê·ªô tin c·∫≠y", value=f"{confidence:.2f}%")
#             else:
#                 st.error("Model ch∆∞a s·∫µn s√†ng.")
#     else:
#         st.info("Vui l√≤ng cung c·∫•p h√¨nh ·∫£nh ·ªü c·ªôt b√™n tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu nh·∫≠n di·ªán.")

# # --- SIDEBAR TH√îNG TIN ---
# st.sidebar.markdown("## üéì Th√¥ng Tin Sinh Vi√™n")
# st.sidebar.divider()
# st.sidebar.markdown(f"""
# - **H·ªç T√™n:** L√™ ƒê·∫∑ng Tu·∫•n B·∫£o
# - **MSV:** 223332815
# - **L·ªõp:** RB&AI-K63
# - **H·ªçc ph·∫ßn:** H·ªçc S√¢u
# """)

# st.sidebar.divider()

import streamlit as st
import tensorflow as tf
from PIL import Image
import numpy as np

# 1. C·∫§U H√åNH GIAO DI·ªÜN CHU·∫®N
st.set_page_config(page_title="AI Human Detection - Tu·∫•n B·∫£o", layout="wide")

# CSS ƒë·ªÉ giao di·ªán c√¢n ƒë·ªëi v√† chuy√™n nghi·ªáp
st.markdown("""
    <style>
    .main { background-color: #f5f7f9; }
    .stAlert { border-radius: 10px; }
    div[data-testid="stMetricValue"] { font-size: 2rem; color: #1E3A8A; }
    </style>
    """, unsafe_allow_html=True)

# 2. H√ÄM N·∫†P M√î H√åNH (S·ª≠ d·ª•ng c·∫•u tr√∫c an to√†n nh·∫•t)
@st.cache_resource
def load_my_model():
    try:
        # T·ª± d·ª±ng khung Sequential ƒë·ªÉ tr√°nh m·ªçi l·ªói Tensor
        base_model = tf.keras.applications.MobileNetV2(
            input_shape=(224, 224, 3), include_top=False, weights=None
        )
        model = tf.keras.Sequential([
            base_model,
            tf.keras.layers.GlobalAveragePooling2D(),
            tf.keras.layers.Dense(1, activation='sigmoid')
        ])
        # N·∫°p file tr·ªçng s·ªë (ƒê·∫£m b·∫£o file n√†y ƒë√£ c√≥ tr√™n GitHub)
        model.load_weights('model_weights.weights.h5')
        return model
    except Exception as e:
        st.error(f"L·ªói n·∫°p m√¥ h√¨nh: {e}")
        return None

model = load_my_model()

# --- GIAO DI·ªÜN CH√çNH ---
st.title("üë§ H·ªá Th·ªëng Nh·∫≠n Di·ªán Ng∆∞·ªùi - MobileNetV2")
st.markdown(f"**Sinh vi√™n:** L√™ ƒê·∫∑ng Tu·∫•n B·∫£o | **MSV:** 223332815 | **L·ªõp:** RB&AI-K63")
st.divider()

# Chia 2 c·ªôt: Tr√°i nh·∫≠p li·ªáu - Ph·∫£i hi·ªÉn th·ªã k·∫øt qu·∫£
col1, col2 = st.columns([1, 1], gap="large")

with col1:
    st.subheader("üì• Nh·∫≠p d·ªØ li·ªáu ·∫£nh")
    source = st.radio("Ch·ªçn ph∆∞∆°ng th·ª©c:", ("T·∫£i ·∫£nh t·ª´ m√°y", "Ch·ª•p t·ª´ Webcam"), horizontal=True)
    
    img_data = None
    if source == "T·∫£i ·∫£nh t·ª´ m√°y":
        img_data = st.file_uploader("K√©o th·∫£ ·∫£nh v√†o ƒë√¢y...", type=["jpg", "png", "jpeg"])
    else:
        img_data = st.camera_input("Ch·ª•p ·∫£nh")

with col2:
    st.subheader("üìä K·∫øt qu·∫£ ph√¢n t√≠ch AI")
    if img_data is not None:
        # 1. Hi·ªÉn th·ªã ·∫£nh ngay l·∫≠p t·ª©c
        image = Image.open(img_data).convert('RGB')
        st.image(image, caption='·∫¢nh ƒë·ªëi t∆∞·ª£ng', use_container_width=True)
        
        # 2. Ch·∫°y d·ª± ƒëo√°n
        if model is not None:
            with st.spinner('ƒêang t√≠nh to√°n x√°c su·∫•t...'):
                # Ti·ªÅn x·ª≠ l√Ω (Rescale 1./255)
                img_resized = image.resize((224, 224))
                img_array = np.array(img_resized).astype(np.float32) / 255.0
                img_array = np.expand_dims(img_array, axis=0)
                
                # D·ª± ƒëo√°n
                prediction = model.predict(img_array)
                prob = float(prediction[0][0])
            
            # 3. Hi·ªÉn th·ªã k·∫øt lu·∫≠n (S·ª≠a d·∫•u theo nh√£n c·ªßa b·∫°n: < 0.5 l√† Ng∆∞·ªùi)
            st.markdown("---")
            if prob < 0.5:
                confidence = (1 - prob) * 100
                st.success(f"## ‚úÖ K·∫æT QU·∫¢: ƒê√ÇY L√Ä NG∆Ø·ªúI")
                st.metric("ƒê·ªô tin c·∫≠y", f"{confidence:.2f}%")
                st.balloons()
            else:
                confidence = prob * 100
                st.error(f"## ‚ùå K·∫æT QU·∫¢: KH√îNG PH·∫¢I NG∆Ø·ªúI")
                st.metric("ƒê·ªô tin c·∫≠y", f"{confidence:.2f}%")
        else:
            st.error("Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi b·ªô n√£o AI. Vui l√≤ng ki·ªÉm tra file weights tr√™n GitHub.")
    else:
        st.info("H·ªá th·ªëng ƒëang ch·ªù d·ªØ li·ªáu ·∫£nh t·ª´ c·ªôt b√™n tr√°i...")

# --- TH√îNG TIN B·ªî SUNG ---
st.sidebar.markdown("### üõ† C√¥ng ngh·ªá s·ª≠ d·ª•ng")
st.sidebar.write("- MobileNetV2 (Transfer Learning)")
st.sidebar.write("- TensorFlow & Streamlit Cloud")
st.sidebar.write("- Image Preprocessing (224x224)")
